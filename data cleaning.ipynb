{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "- Here we are combining the data of Indeed and Seek into one data frame and perform all the clenaing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')#/, category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_file = './data/indeed_data.csv'\n",
    "seek_file = './data/seek_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indeed_data = pd.read_csv(indeed_file)\n",
    "df_seek_data = pd.read_csv(seek_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((337, 5), (1829, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indeed_data.shape ,  df_seek_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seek_data['salary'].fillna('None',inplace=True)\n",
    "df_seek_data['job_desc'].fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_data = pd.concat([df_seek_data, df_indeed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2166, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>job_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics Consultant / BI Developer</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>None</td>\n",
       "      <td>Aginic</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data and Insights Reporting Analyst.</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>None</td>\n",
       "      <td>ELMO Software Limited</td>\n",
       "      <td>&lt;div class=\"tempmargin\"&gt;\\r\\n      &lt;h1 class=\"j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Competitive Day Rate</td>\n",
       "      <td>Hydrogen Group Pty Ltd</td>\n",
       "      <td>&lt;div class=\"tempmargin\"&gt;\\r\\n      &lt;h1 class=\"j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>$75,000 - $84,999 base + super</td>\n",
       "      <td>Salient Group</td>\n",
       "      <td>&lt;div class=\"tempmargin\"&gt;\\r\\n      &lt;h1 class=\"j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Visualisation Analyst</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Super</td>\n",
       "      <td>Ambition Technology</td>\n",
       "      <td>&lt;div class=\"tempmargin\"&gt;\\r\\n      &lt;h1 class=\"j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  job_title   location  \\\n",
       "0  Data Analytics Consultant / BI Developer   Brisbane   \n",
       "1      Data and Insights Reporting Analyst.     Sydney   \n",
       "2                              Data Analyst     Sydney   \n",
       "3                              Data Analyst     Sydney   \n",
       "4                Data Visualisation Analyst  Melbourne   \n",
       "\n",
       "                           salary                 company  \\\n",
       "0                            None                  Aginic   \n",
       "1                            None   ELMO Software Limited   \n",
       "2            Competitive Day Rate  Hydrogen Group Pty Ltd   \n",
       "3  $75,000 - $84,999 base + super           Salient Group   \n",
       "4                           Super     Ambition Technology   \n",
       "\n",
       "                                            job_desc  \n",
       "0                                               None  \n",
       "1  <div class=\"tempmargin\">\\r\\n      <h1 class=\"j...  \n",
       "2  <div class=\"tempmargin\">\\r\\n      <h1 class=\"j...  \n",
       "3  <div class=\"tempmargin\">\\r\\n      <h1 class=\"j...  \n",
       "4  <div class=\"tempmargin\">\\r\\n      <h1 class=\"j...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to remove tags and newline character from job descirption\n",
    "def remove_tags(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "def remove_newline_char(raw_html):\n",
    "    cleanr = re.compile(r'[^ \\w\\.]')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing html tags\n",
    "df_job_data['job_desc'] = df_job_data['job_desc'].apply(lambda x: remove_tags(x) if x!='None' else x)\n",
    "\n",
    "#removing new line character\n",
    "df_job_data['job_desc'] = df_job_data['job_desc'].apply(lambda x: remove_newline_char(x) if x!='None' else x)\n",
    "\n",
    "#removing punctuation mark\n",
    "df_job_data['job_desc'] = df_job_data['job_desc'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "#removing double spaces if any\n",
    "df_job_data['job_desc'] = df_job_data['job_desc'].str.replace('      ',' ')\n",
    "\n",
    "#converting title and text into lower case\n",
    "df_job_data['job_desc'] = df_job_data['job_desc'].apply(lambda x: x.lower() if x!='None' else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary cleaning\n",
    "\n",
    "#removing new line character if any\n",
    "df_job_data['salary'] = df_job_data['salary'].str.replace('\\n', '')\n",
    "\n",
    "#removing ',' from salary\n",
    "df_job_data['salary'] = df_job_data['salary'].str.replace(',', '')\n",
    "\n",
    "#removing '$' from salary\n",
    "df_job_data['salary'] = df_job_data['salary'].str.replace('$', '')\n",
    "\n",
    "#converting the slares into lower case\n",
    "df_job_data['salary'] = df_job_data['salary'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_data['salary_period'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('year'), 'salary_period'] = 'year'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('month'), 'salary_period'] = 'month'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('week'), 'salary_period'] = 'week'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('day'), 'salary_period'] = 'day'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('hour'), 'salary_period'] = 'hour'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('p.h'), 'salary_period'] = 'hour'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('/hr'), 'salary_period'] = 'hour'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('p.d'), 'salary_period'] = 'day'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('p.a'), 'salary_period'] = 'year'\n",
    "df_job_data.ix[df_job_data['salary'].str.contains('pd'), 'salary_period'] = 'day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating and new data frame to work on data that has salaries to clean then and drop all the values form the original df that have slaries. \n",
    "#After working on salaries we can concat these two data frames\n",
    "salary_data_df = df_job_data[df_job_data['salary'] != 'none']\n",
    "df_job_data = df_job_data[~df_job_data.isin(salary_data_df)].dropna(how='all')\n",
    "df_job_data['salary'].replace('none',np.nan, inplace=True)\n",
    "df_job_data['salary'] = df_job_data['salary'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the salary having 'to' e.g 80000 to 90000 by '-' e.g 80000 - 90000\n",
    "#convert 'k' with '000' e.g 80k - 90k will become 80000 - 90000\n",
    "\n",
    "salary_data_df['salary'] = salary_data_df['salary'].str.replace('to', '-', regex=True)\n",
    "salary_data_df['salary'] = salary_data_df['salary'].str.replace('k', '000', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove all charactres from salary values so we will only be working with numeirc values\n",
    "def extract_values_with_only_letter(value):\n",
    "    result = re.sub(r\"[a-z]\", \"\", value, flags=re.I)\n",
    "    final_result = re.sub(r\"\\W\", \"\", result, flags=re.I)\n",
    "    return final_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we put a salary period in data frame based on some character values like p.a, year, month week(e.g 80000-90000 a year).\n",
    "#There are some yearly salaries which are not able tp generate salary period as year because there is no chracter\n",
    "#(e.g 8000-90000)\n",
    "# Therefore, creating a new column called is salary so we can use this column to put the values of salary period as year\n",
    "#where no period is mentioned.\n",
    "salary_data_df['is_salary'] = salary_data_df['salary'].apply(lambda x:extract_values_with_only_letter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all the salaries which doesn't have salary value to null and concat to the main data frame\n",
    "#after calling above function all the slary values that don't have numeric values in them will become empty string.\n",
    "#so we can drop them from salary_data_df and concat it to df_job_data(all data without salaries)\n",
    "salary_data_without_salary = salary_data_df[salary_data_df['is_salary']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_without_salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concating no salary data drom salary_data_df to df_job-data\n",
    "salary_data_without_salary['salary'] = np.nan\n",
    "salary_data_without_salary['salary'] = salary_data_without_salary['salary'].astype('float')\n",
    "df_job_data = pd.concat([df_job_data,salary_data_without_salary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop all rows that only contains characters in salary(no salary data) (is_salary is '')\n",
    "salary_data_df.drop(salary_data_df[salary_data_df['is_salary']==''].index,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now after dropping all the rows that don't have any salary information you need to fill remaining salary period column values\n",
    "#with 'Year' becase the data which is not labled are all of year(e.g 80000-90000, not 80000-90000 a year) \n",
    "salary_data_df['salary_period'].fillna('year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the is_salary column as we don't need\n",
    "salary_data_df.drop('is_salary',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year     362\n",
       "day      151\n",
       "hour      49\n",
       "week       5\n",
       "month      4\n",
       "Name: salary_period, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_df['salary_period'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate seprate data frame for each salary period so that the computation will be easy\n",
    "year_salaries = salary_data_df[salary_data_df['salary_period'] == 'year']\n",
    "month_salaries = salary_data_df[salary_data_df['salary_period'] == 'month']\n",
    "week_salaries = salary_data_df[salary_data_df['salary_period'] == 'week']\n",
    "day_salaries = salary_data_df[salary_data_df['salary_period'] == 'day']\n",
    "hour_salaries = salary_data_df[salary_data_df['salary_period'] == 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all month salary values are not numeric salaries(contains alpha numeric values so can't handeled by earlier regex function)\n",
    "#so we can make them null and concate it with actual job data\n",
    "month_salaries['salary'] = np.nan\n",
    "month_salaries['salary'] = month_salaries['salary'].astype('float')\n",
    "df_job_data = pd.concat([df_job_data,month_salaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the week salary data also have alpha numeric values but not salaries so remove them and concat them to original data frame\n",
    "df_job_data = pd.concat([df_job_data,week_salaries.iloc[0:3,:]])\n",
    "df_job_data['salary'] = np.nan\n",
    "df_job_data['salary'] = df_job_data['salary'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non numeric salary info\n",
    "week_salaries.drop(week_salaries.iloc[0:3,:]['salary'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1602, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_salaries.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year salary has some values which are not salaries just text. These are also alphanumeric but not salaries, So dropping them.\n",
    "df_job_data = pd.concat([df_job_data,year_salaries.iloc[[16,25,41,44,47,48,60,65,67,76,77,86,91,95,101,104,106,118,123,137,142,145,155,170,184,189,197,203,205,215,224,232,234,243,259,263,264,297,306,313,316,62,154,170],:]])\n",
    "df_job_data['salary'] = np.nan\n",
    "df_job_data['salary'] = df_job_data['salary'].astype(float)\n",
    "year_salaries.drop(year_salaries.iloc[[16,25,41,44,47,48,60,65,67,76,77,86,91,95,101,104,106,118,123,137,142,145,155,170,184,189,197,203,205,215,224,232,234,243,259,263,264,297,306,313,316,62,154,170],:].index,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciton to extract he numbers from salary information to convert them to numeric salary information\n",
    "def extract_numbers(value): \n",
    "    result = re.sub(r\"[a-z]\", \"\", value, flags=re.I)\n",
    "    final_result = re.sub(\"[+|()|/]\", \"\", result)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying above function to salary of each salary period\n",
    "hour_salaries['salary'] = hour_salaries['salary'].apply(lambda x: extract_numbers(x))\n",
    "week_salaries['salary'] = week_salaries['salary'].apply(lambda x: extract_numbers(x))\n",
    "day_salaries['salary'] = day_salaries['salary'].apply(lambda x: extract_numbers(x))\n",
    "year_salaries['salary'] = year_salaries['salary'].apply(lambda x: extract_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to handle all possible salary cleaning condition\n",
    "def split_sal(i,salary_period):\n",
    "    #try:\n",
    "   # print(i)\n",
    "    if '-' in i:\n",
    "        splt = i.split('-',1)\n",
    "        #print(i)\n",
    "        splt[0] = splt[0].strip()\n",
    "        splt[1] = splt[1].strip()\n",
    "        if splt[0] == '' and '..' in splt[1]:\n",
    "            #print(i)\n",
    "            #print('here1')\n",
    "            first = float(splt[1].split(' ',1)[0])\n",
    "            second =float(splt[1].split(' ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '!' not in splt[0] and '..' in splt[1] and '%' not in splt[1] and len(splt[0])>=4:\n",
    "            #print(i)\n",
    "            #print('here2')\n",
    "            first = float(splt[0])\n",
    "            second = float(splt[1].split(' ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '!' not in splt[0] and '..' in splt[1] and '%' not in splt[1] and len(splt[0])<=3 and salary_period=='year':\n",
    "            #print(i)\n",
    "            #print('here3')\n",
    "            first = float(splt[0]+'000')\n",
    "            second = float(splt[1].split(' ',1)[0]+'000')\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '!' not in splt[0] and '..' in splt[1] and '%' not in splt[1]:\n",
    "            #print(i)\n",
    "            #print('here3')\n",
    "            first = float(splt[0])\n",
    "            #second = float(splt[1].replace('..',''))\n",
    "            second = float(splt[1].split(' ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and ':' not in splt[0] and  '%' in splt[1] and '..' not in splt[1] and len(splt[1])>3:\n",
    "            #print(i)\n",
    "            #print('here4')\n",
    "            first = float(splt[0].strip())\n",
    "            second = float(splt[1].split(' ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and ':' not in splt[0] and  '%' in splt[1] and '..' not in splt[1] and len(splt[1])<=3: #changed\n",
    "            #print(i)\n",
    "            #print('here5')\n",
    "#             first = float(splt[0])#.strip())\n",
    "#             second = float(splt[1].split(' ',1)[0])\n",
    "            return float(splt[0])\n",
    "        elif splt[0] != ' ' and ':' in splt[0] and  '%' in splt[1] and '..' not in splt[1]:\n",
    "            #print('here6')\n",
    "            first = float(splt[0].split(':',1)[1].strip())\n",
    "            second = float(splt[1].split('  ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '%' in splt[1] and '..' in splt[1]:\n",
    "            #print('here7')\n",
    "            first = float(splt[0].strip())\n",
    "            second = float(splt[1].replace('..','').split('  ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '..' not in splt[0] and '..' not in splt[1] and len(splt[0])>=4 and len(splt[1])>=4 and ' ' not in splt[1] and salary_period == 'year':\n",
    "            #print(i)\n",
    "            #print('here8')\n",
    "            if '.' in splt[0] and '.' in splt[1]:\n",
    "                first = float(splt[0].split('.',1)[0] + '000')\n",
    "                second = float(splt[1].split('.',1)[0] + '000')\n",
    "            else:\n",
    "                first = float(splt[0])\n",
    "                second = float(splt[1].strip().split('  ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '..' not in splt[1] and len(splt[0])>=4 and len(splt[1])>=4 and ' ' not in splt[1]:\n",
    "            #print(i)\n",
    "            #print('here9')\n",
    "            first = float(splt[0].split(' ',1)[0])\n",
    "            second = float(splt[1])\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != ' ' and '..' not in splt[1] and len(splt[0])>=4 and len(splt[1])>=4 and ' ' in splt[1] and ' ' not in splt[0]:\n",
    "            #print('here10')\n",
    "            first = float(splt[0].strip())\n",
    "            second = float(splt[1].strip().split(' ',1)[0])\n",
    "            return (first+second)/2 \n",
    "        elif splt[0] != ' ' and '..' not in splt[1] and len(splt[0])>=4 and len(splt[1])>=4 and ' ' in splt[1].strip() and ' ' in splt[0].strip():\n",
    "            #print('here11')\n",
    "            first = float(''.join(splt[0].strip().split(' ',1)))\n",
    "            second = float(''.join(splt[1].strip().split(' ',1)))\n",
    "            return (first+second)/2\n",
    "        elif splt[0] != '' and len(splt[0])<=3 and len(splt[1])<=3 and salary_period == 'year':#for day\n",
    "            #print('here16')\n",
    "            #print(splt[0])\n",
    "            first = float(splt[0]+'000')\n",
    "            second = float(splt[1] + '000')\n",
    "            return (first + second)/2\n",
    "        elif splt[0] != '' and ':' in splt[0] and len(splt[1])<=3 and salary_period == 'year':#for day\n",
    "            #print('here16')\n",
    "            #print(splt[0])\n",
    "            first = float(splt[0].split(' ',1)[1] +'000')\n",
    "            second = float(splt[1] + '000')\n",
    "            return (first + second)/2\n",
    "        elif splt[0] != '' and '..' not in splt[1] and len(splt[0])<=4 and len(splt[1])<=3 and salary_period == 'day':#for day\n",
    "            #print('here16')\n",
    "            #print(splt[0])\n",
    "            if '.' in splt[0]:\n",
    "                #print('here')\n",
    "                first = float(splt[0].replace('.',''))\n",
    "            else:\n",
    "                first = float(splt[0])\n",
    "            second = float(splt[1])\n",
    "            return (first + second)/2\n",
    "#         elif splt[0] != '' and '..' in splt[1] and salary_period == 'day':\n",
    "#             print('here')\n",
    "#             first = float(splt[0])\n",
    "#             second = float(splt[1].split(' ',1)[0])\n",
    "#             return(first+second)/2\n",
    "        elif splt[0] == '' and '..' not in splt[1] and len(splt[0])<=3 and len(splt[1])<=3 and salary_period == 'day':#for day\n",
    "            #print('here17')\n",
    "            return float(splt[1])\n",
    "        elif splt[0] != '' and '.' not in splt[1] and len(splt[0])<=3 and salary_period == 'hour':\n",
    "            #print('here 18')\n",
    "            first = float(splt[0])\n",
    "            second = float(splt[1])\n",
    "            return (first + second)/2\n",
    "        elif splt[0] != '' and '.' in splt[1] and len(splt[0])<=3 and salary_period == 'hour':\n",
    "            #print('here 19')\n",
    "            first = float(splt[0])\n",
    "            second = float(splt[1].split(' ',1)[0])\n",
    "            return (first + second)/2 \n",
    "        elif splt[0] != '' and '.' in splt[1] and len(splt[0])>=3 and salary_period == 'hour':\n",
    "            #print('here 19')\n",
    "            first = float(splt[0].split('.',1)[0])\n",
    "            second = float(splt[1].split('.',1)[0])\n",
    "            return (first + second)/2 \n",
    "        \n",
    "        elif splt[0] != ' ' and '!' in splt[0]:\n",
    "            first = float(splt[0].split(' ',1)[1].strip())\n",
    "            second = float(splt[1].strip().split(' ',1)[0])\n",
    "            return (first+second)/2\n",
    "        elif splt[0]!='' and len(splt[1].strip())>=4 and len(splt[1].strip()) <=6 and len(splt[0].strip())<=3:\n",
    "            #print('here12')\n",
    "            if '.' in splt[1] and ' ' not in splt[1] and salary_period == 'year': #changed in year to match with day\n",
    "                return float(splt[1].split(' ',1)[0] + '000')\n",
    "            if '.' in splt[1] and salary_period == 'day':\n",
    "                return float(splt[1].split(' ',1)[0])\n",
    "            if ' ' in splt[1]:\n",
    "                return float(splt[1].split(' ',1)[0] + '000')\n",
    "            else:\n",
    "                return float(splt[1])#.strip())\n",
    "        elif splt[0].strip()!='' and len(splt[1].strip()) >=6 and len(splt[0].strip())<=3:\n",
    "            #print(i)\n",
    "            #print('here13')\n",
    "            return float(splt[1].split(' ',1)[0])\n",
    "        elif splt[0] == '' and '-' in splt[1]:\n",
    "            #print(i)\n",
    "            #print('here14')\n",
    "            value = splt[1].split('-',1)\n",
    "            first = float(value[0].split('.',1)[1].strip())\n",
    "            second = float((''.join(value[1].split('.',1))).strip())\n",
    "            return (first+second)/2\n",
    "        elif splt[0] == '' and len(splt[1])<=6:\n",
    "            #print('here15')\n",
    "            return float(splt[1].strip())\n",
    "        elif splt[0] == '' and len(splt[1])>6:\n",
    "            #print('here16')\n",
    "            return float(splt[1].split(' ',1)[0])\n",
    "           \n",
    "    #except:\n",
    "    else:\n",
    "        i = i.strip()\n",
    "        if salary_period == 'year' and len(i.strip())<=3:\n",
    "            #print('here17')\n",
    "            if len(i.strip())<=2:\n",
    "                return float(i.strip()+'000')\n",
    "            elif len(i.strip())==3:\n",
    "                return float(i.strip()+'000')\n",
    "        elif ' ' in i:\n",
    "            #print('here18')\n",
    "            return float(i.split(' ',1)[0].strip())\n",
    "        else: \n",
    "            #print('here19')\n",
    "            return float(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying this function to all salary information of different salary period\n",
    "year_salaries['salary']= year_salaries['salary'].apply(lambda x: split_sal(x,'year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_salaries['salary']=week_salaries['salary'].apply(lambda x: split_sal(x,'week'))\n",
    "week_salaries['salary'] = week_salaries['salary'] * 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_salaries['salary'] = day_salaries['salary'].apply(lambda x: split_sal(x,'day'))\n",
    "day_salaries['salary'] = day_salaries['salary'] * 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_salaries['salary'] = hour_salaries['salary'].apply(lambda x: split_sal(x,'hour'))\n",
    "hour_salaries['salary'] = hour_salaries['salary'] * 2080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinatinng salary information of all period\n",
    "all_period_salaries = pd.concat([year_salaries, month_salaries, week_salaries, day_salaries, hour_salaries], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_period_salaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1646, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating cleaned salaries to original data frame\n",
    "df_job_data = pd.concat([df_job_data, all_period_salaries], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the duplicate job information\n",
    "df_job_data.drop_duplicates(['company','job_title','location'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1856, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sydney                                    699\n",
       "Melbourne                                 435\n",
       "Brisbane                                  206\n",
       "ACT                                       104\n",
       "Melbourne VIC                              88\n",
       "Perth                                      85\n",
       "Adelaide                                   49\n",
       "Sydney NSW                                 35\n",
       "Newcastle, Maitland & Hunter               12\n",
       "Gosford & Central Coast                    11\n",
       "Brisbane QLD                               11\n",
       "Australia                                  11\n",
       "Gold Coast                                 10\n",
       "Canberra ACT                                8\n",
       "Melbourne City Centre VIC                   8\n",
       "South West Coast VIC                        8\n",
       "Darwin                                      5\n",
       "Ballarat & Central Highlands                3\n",
       "Mulgrave VIC                                3\n",
       "Wollongong, Illawarra & South Coast         3\n",
       "Hobart                                      3\n",
       "Sunshine Coast                              3\n",
       "Perth WA                                    2\n",
       "Parkville VIC                               2\n",
       "Victoria                                    2\n",
       "Gladesville NSW                             2\n",
       "Dandenong VIC                               2\n",
       "Brisbane Central Business District QLD      2\n",
       "Blue Mountains & Central West               2\n",
       "Sydney Central Business District NSW        2\n",
       "                                         ... \n",
       "Liverpool NSW                               1\n",
       "Artarmon NSW                                1\n",
       "Sydney Western Suburbs NSW                  1\n",
       "Mile End SA                                 1\n",
       "Gladstone & Central QLD                     1\n",
       "Parramatta NSW                              1\n",
       "Port Macquarie & Mid North Coast            1\n",
       "Port Melbourne VIC                          1\n",
       "Russell ACT                                 1\n",
       "Sydney Olympic Park NSW                     1\n",
       "Dubbo & Central NSW                         1\n",
       "Darwin NT                                   1\n",
       "Barton ACT                                  1\n",
       "Yagoona NSW                                 1\n",
       "Gold Coast QLD                              1\n",
       "Moonee Ponds VIC                            1\n",
       "Belconnen ACT                               1\n",
       "South Melbourne VIC                         1\n",
       "St Lucia QLD                                1\n",
       "Inner West NSW                              1\n",
       "Richmond VIC                                1\n",
       "Footscray VIC                               1\n",
       "East Melbourne VIC                          1\n",
       "Bella Vista NSW                             1\n",
       "Clayton VIC                                 1\n",
       "Darlinghurst NSW                            1\n",
       "Newstead QLD                                1\n",
       "Bundaberg & Wide Bay Burnett                1\n",
       "Scoresby VIC                                1\n",
       "Queensland                                  1\n",
       "Name: location, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_data['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean location information\n",
    "def clean_location(location):\n",
    "    if 'VIC' in location:\n",
    "        return 'Melbourne'\n",
    "    if 'NSW' in location:\n",
    "        return 'Sydney'\n",
    "    if 'Brisbane' in location:\n",
    "        return 'Brisbane'\n",
    "    if 'Adelaide' in location:\n",
    "        return 'Adelaide'\n",
    "    if 'Perth' in location:\n",
    "        return 'Perth'\n",
    "    if 'Gold Coast' in location:\n",
    "        return 'Gold Coast'\n",
    "    else: \n",
    "        return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_data['location'] = df_job_data['location'].apply(lambda x:clean_location(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_data.drop(['is_salary','salary_period'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving it to csv(Don't run)\n",
    "#df_job_data.to_csv('./data/cleaned_job_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
